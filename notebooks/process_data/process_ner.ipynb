{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3276e5ef-27d7-4a3f-a4af-984c3ba8fe5c",
   "metadata": {},
   "source": [
    "# CLUE-NER数据预处理\n",
    "- 数据分析\n",
    "- 数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90da426-f64a-4657-a3ce-fd43954d1c52",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "35dd14bf-da2d-4dab-b672-313a3b844381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import srsly\n",
    "from datasets import Dataset, load_from_disk, DatasetDict, ClassLabel, Sequence\n",
    "from transformers import AutoTokenizer, DataCollatorForTokenClassification, BertTokenizer, BertTokenizerFast\n",
    "from spacy.training import offsets_to_biluo_tags\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "from spacy.tokens import Doc\n",
    "import jieba\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9ebefbb9-727e-4d18-816c-37c2d4644c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = list(srsly.read_jsonl('clue_ner/train.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e1e3ee9d-f585-4267-be4f-20909e157f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0]['text'] = '浙商银行企业信贷部叶老桂博士则从另一个角度对五道门槛进行了解读.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "deb83cb2-5c7f-4378-ba9c-5aae568b4616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'浙商银行企业信贷部叶老桂博士则从另一个角度对五道门槛进行了解读.'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "68409f01-e6f0-4e04-bc47-16842990fbf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '据了解，日前有媒体上刊发了题为《招商银行：投资永隆银行浮亏逾百亿港元》的文章，',\n",
       " 'label': {'book': {'《招商银行：投资永隆银行浮亏逾百亿港元》': [[15, 34]]},\n",
       "  'company': {'招商银行': [[16, 19]], '永隆银行': [[23, 26]]}}}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[1506]  #这个数据出现了嵌套 删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "156427d6-7efe-42ca-a630-b19c700beed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_data[1506]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "113f32f8-c3a1-4370-93f9-6c84994b0813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '姜山：切沃在迎战近况极佳的尤文之前刚刚换帅，不过亚齐尼的接任者也很难给人太多的信心———',\n",
       " 'label': {'organization': {'切沃': [[3, 4]], '尤文': [[13, 14]]},\n",
       "  'name': {'姜山': [[0, 1]], '亚齐尼': [[24, 26]]}}}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[1506]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d1f6a721-f7bc-4024-b671-89c1ca9a356f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '当记者在泗水街头随便询问10余名市民却发现，只有寥寥几人知道当地有如此神奇的东西。',\n",
       " 'label': {'address': {'泗水': [[4, 5]]}, 'position': {'记者': [[1, 2]]}}}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[24] = {'text': '当记者在泗水街头随便询问10余名市民却发现，只有寥寥几人知道当地有如此神奇的东西。',\n",
    " 'label': {'address': {'泗水': [[4, 5]]}, 'position': {'记者': [[1, 2]]}}}\n",
    "train_data[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6cb44a25-071e-4fe6-80e3-a315c8112791",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[1722]['label'] = {'game': {'dota': [[27, 30]]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a630d27c-11cf-423c-a68e-3b8dd7c97636",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[1986]['label'] = {'address': {'香港': [[28, 29]]}, 'movie': {'《狩猎聚会》': [[4, 9]], 'thehuntingparty': [[11, 25]], '猎狐行动': [[33, 36]]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "066e1276-2d23-4530-8a05-11a90eb2db7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[3016] = {'text': 'Moon星际2无力GSL,A级预选落败',\n",
    " 'label': {'game': {'星际2': [[4, 6]]},\n",
    "  'organization': {'GSL': [[9, 11]]},\n",
    "  'name': {'Moon': [[0, 3]]}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "16783b34-6fe0-4ba8-9a53-c8f8a9ec24a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Moon星际2无力GSL,A级预选落败',\n",
       " 'label': {'game': {'星际2': [[4, 6]]},\n",
       "  'organization': {'GSL': [[9, 11]]},\n",
       "  'name': {'Moon': [[0, 3]]}}}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[3016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b631118b-787f-4a6c-9083-1c3d0dd22832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'StarCraft2 Forum在倒计时的上方有一行字：“它将来临……”',\n",
       " 'label': {'game': {'StarCraft2': [[0, 9]]}}}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[5175] = {'text': 'StarCraft2 Forum在倒计时的上方有一行字：“它将来临……”',\n",
    " 'label': {'game': {'StarCraft2': [[0, 9]]}}}\n",
    "train_data[5175]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1d638144-e10d-48e5-afa5-8845fe13a0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '朴茨茅斯队vs ac米兰队两队在欧洲三大杯历史上没有交锋战绩。',\n",
       " 'label': {'organization': {'朴茨茅斯队': [[0, 4]], 'ac米兰队': [[8, 12]]}}}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[6554] = {'text': '朴茨茅斯队vs ac米兰队两队在欧洲三大杯历史上没有交锋战绩。',\n",
    " 'label': {'organization': {'朴茨茅斯队': [[0, 4]], 'ac米兰队': [[8, 12]]}}}\n",
    "train_data[6554]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cb11a485-7635-4cca-874d-c776d67d7a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '最后一种模式和War3DotA中的死亡模式类似，当你的英雄死亡，',\n",
       " 'label': {'game': {'War3': [[7, 10]], 'DotA': [[11, 14]]}}}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[6907]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "057d65c2-df7f-435e-8313-3570aa0b82b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '彭小军认为，国内银行现在走的是台湾的发卡模式，先通过跑马圈地再在圈的地里面选择客户，',\n",
       " 'label': {'address': {'台湾': [[15, 16]]}, 'name': {'彭小军': [[0, 2]]}}}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data = list(srsly.read_jsonl('clue_ner/dev.json'))\n",
    "valid_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2738a3ff-1e86-4de4-ae7b-4770c3e81303",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 数据分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "324d3f9a-530f-4305-8334-84179d70e054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_df(data):\n",
    "    data_ls = []\n",
    "    for d in data:\n",
    "        text = d['text']\n",
    "        for label in d['label']:\n",
    "            for span in d['label'][label]:\n",
    "                start_index = d['label'][label][span][0][0]\n",
    "                end_index = d['label'][label][span][0][1]\n",
    "                data_ls.append([text, span, label, start_index, end_index])\n",
    "    return pd.DataFrame(data_ls, columns=['text', 'span','label', 'start', 'end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b34325ec-6759-4659-8b6d-b1919e1d054b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = to_df(train_data)\n",
    "valid_df = to_df(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2256a21d-745c-4237-af9a-1303ce7e0271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name            451\n",
       "position        425\n",
       "company         366\n",
       "address         364\n",
       "organization    344\n",
       "game            287\n",
       "government      244\n",
       "scene           199\n",
       "book            152\n",
       "movie           150\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5e7cd7-082f-4f8c-8661-6924b2fd5913",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 数据处理为huggingface 和 spacy 格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1aef6de7-b29e-4be9-8b2f-303766bdb8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('hfl/chinese-roberta-wwm-ext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "03ad0c3c-75b6-413c-9133-eac13f9c4298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens({'additional_special_tokens':[\"A\", 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V','W','X','Y','Z', '0', '1','2','3','4','5','6','7','8','9', 'ac','米兰']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e998b4b2-a4a6-43a8-9db9-88c36af35a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S', 'ta', '##r', 'C', 'ra', '##ft', '2', 'F', 'or', '##um', '在', '倒', '计', '时', '的', '上', '方', '有', '一', '行', '字', '：', '[UNK]', '它', '将', '来', '临', '[UNK]', '[UNK]', '[UNK]']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.tokenize('StarCraft2 Forum在倒计时的上方有一行字：“它将来临……”'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "177c2259-2634-48ba-881c-a1760767f11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank('zh')\n",
    "tokens = tokenizer.tokenize('今天非常firable')\n",
    "doc = Doc(nlp.vocab, words=tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "53046965-cf84-4f13-b131-3affb5528d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process(data_ls):\n",
    "    dataset = {'tokens':[], 'labels':[]}\n",
    "    docs = []\n",
    "    for data in tqdm(data_ls):\n",
    "        entities = []\n",
    "        dataset['tokens'].append([s for s in data['text']])\n",
    "        mapping = tokenizer(data['text'], add_special_tokens=False, return_offsets_mapping=True)['offset_mapping']\n",
    "        tokens = tokenizer.tokenize(data['text'], add_special_tokens=False)\n",
    "        doc = Doc(nlp.vocab, words=tokens)\n",
    "        spans = []\n",
    "        for label in data['label']:\n",
    "            for ent in data['label'][label]:\n",
    "                char_start = data['label'][label][ent][0][0]\n",
    "                char_end = data['label'][label][ent][0][1]+1\n",
    "                entity = []\n",
    "                # try:\n",
    "                for i, v in enumerate(mapping):\n",
    "                    if v[0] == char_start and v[1] == char_end:\n",
    "                        entity.append(i)\n",
    "                        entity.append(i+1)\n",
    "                    if v[0] == char_start and v[1]!= char_end:\n",
    "                        entity.append(i)\n",
    "                    elif v[1] == char_end and v[0] != char_start:\n",
    "                        entity.append(i)\n",
    "                entity.append(label)\n",
    "                # print(entity)\n",
    "                assert len(entity) == 3\n",
    "                # except AssertionError:\n",
    "                #     print(entity)\n",
    "                entities.append(entity)\n",
    "                e_span = spacy.tokens.Span(doc, entity[0], entity[1], label)\n",
    "                spans.append(e_span)\n",
    "        doc.set_ents(spans)\n",
    "        docs.append(doc)\n",
    "        tags = [t.ent_iob_ if t.ent_iob_ == 'O' else t.ent_iob_ + '-' + t.ent_type_ for t in doc ]\n",
    "        dataset['labels'].append(tags)\n",
    "    return dataset, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "526013d7-4472-45d4-939c-b6c50eb635a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10747/10747 [00:05<00:00, 1969.46it/s]\n",
      "100%|██████████| 1343/1343 [00:00<00:00, 2147.58it/s]\n"
     ]
    }
   ],
   "source": [
    "train_ds, train_docs= process(train_data)\n",
    "valid_ds, valid_docs = process(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "00785a90-06d8-4bc9-8151-0446dacac04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "过多地依赖范布隆霍斯特、马凯和托马森（正是从费耶诺德辗转ac米兰、斯图加特和维拉利尔，\n",
      "{'organization': {'费耶诺德': [[22, 25]], '米兰': [[30, 31]], '斯图加特': [[33, 36]], '维拉利尔': [[38, 41]]}, 'name': {'范布隆霍斯特': [[5, 10]], '马凯': [[12, 13]], '托马森': [[15, 17]]}}\n",
      "['过', '多', '地', '依', '赖', '范', '布', '隆', '霍', '斯', '特', '、', '马', '凯', '和', '托', '马', '森', '（', '正', '是', '从', '费', '耶', '诺', '德', '辗', '转', 'ac', '米兰', '、', '斯', '图', '加', '特', '和', '维', '拉', '利', '尔', '，']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (1, 2),\n",
       " (2, 3),\n",
       " (3, 4),\n",
       " (4, 5),\n",
       " (5, 6),\n",
       " (6, 7),\n",
       " (7, 8),\n",
       " (8, 9),\n",
       " (9, 10),\n",
       " (10, 11),\n",
       " (11, 12),\n",
       " (12, 13),\n",
       " (13, 14),\n",
       " (14, 15),\n",
       " (15, 16),\n",
       " (16, 17),\n",
       " (17, 18),\n",
       " (18, 19),\n",
       " (19, 20),\n",
       " (20, 21),\n",
       " (21, 22),\n",
       " (22, 23),\n",
       " (23, 24),\n",
       " (24, 25),\n",
       " (25, 26),\n",
       " (26, 27),\n",
       " (27, 28),\n",
       " (28, 30),\n",
       " (30, 32),\n",
       " (32, 33),\n",
       " (33, 34),\n",
       " (34, 35),\n",
       " (35, 36),\n",
       " (36, 37),\n",
       " (37, 38),\n",
       " (38, 39),\n",
       " (39, 40),\n",
       " (40, 41),\n",
       " (41, 42),\n",
       " (42, 43)]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=4222\n",
    "print(train_data[index]['text'])\n",
    "print(train_data[index]['label'])\n",
    "print(tokenizer.tokenize(train_data[index]['text']))\n",
    "tokenizer(train_data[index]['text'], return_offsets_mapping=True, add_special_tokens=False)['offset_mapping']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b135b197-8eca-4290-9c83-f9d5a4c51a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-game',\n",
       " 'I-game',\n",
       " 'I-game',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds['labels'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b4c94fc5-654f-468c-8b74-c1995fc88ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sp, valid_sp = DocBin(docs=train_docs), DocBin(docs=valid_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "0f168259-8511-44fd-a51d-4ce18c784809",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sp.to_disk('cluener_train.spacy')\n",
    "valid_sp.to_disk('cluener_valid.spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "9c7577a3-7c6b-4a79-bb02-6ff98953baed",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(DocBin().from_disk(path='cluener_train.spacy').get_docs(nlp.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b2c457e6-4c6a-4b25-977d-56a311c5b617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d474ac25-6b2d-48cd-8782-702eaf209e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hf = Dataset.from_dict(train_ds)\n",
    "valid_hf = Dataset.from_dict(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8fbf380a-08e8-46ce-ba0e-a0cfb1274d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict()\n",
    "dataset['train'] = train_hf\n",
    "dataset['validation'] = valid_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f3fde513-1ead-44c6-8965-fb0f0ec40aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.save_to_disk('clue_ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e88d74b5-1131-42a9-864b-d0f258b44341",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_from_disk('clue_ner/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "85c96de9-b3b5-4aea-8578-c6589baff47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['主', '要', '属', '于', '结', '构', '性', '理', '财', '产', '品', '。', '上', '周', '交', '通', '银', '行', '发', '行', '了', '“', '天', '添', '利', '”', '系', '列', '理', '财', '产', '品', '，', '投', '资', '者', '在', '封', '闭', '期', '申', '购', '该', '系', '列', '理', '财', '产', '品', '，'], 'labels': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-company', 'I-company', 'I-company', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']}\n"
     ]
    }
   ],
   "source": [
    "print(ds['train'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "ddc1c237-2c5c-47a9-a155-59fdfb52c997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_transform(example):\n",
    "        tokens = example['tokens'][0]\n",
    "        inputs = tokenizer(tokens, is_split_into_words=True, padding='max_length', max_length=50)\n",
    "        inputs = dict(zip(inputs.keys(), map(torch.tensor, inputs.values())))\n",
    "        labels = example['labels'][0]\n",
    "        # print(labels)\n",
    "        labels = [-100] + [label2id[label] for label in labels] \n",
    "        labels = labels + (50 - len(labels)) * [-100]\n",
    "        labels = torch.tensor(labels)\n",
    "        assert len(labels) == len(inputs['input_ids'])\n",
    "        return {'inputs':[inputs], 'labels':[labels]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "ffba2e83-16b9-414c-869c-88e1d59cf56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.set_transform(set_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "ae412c86-db99-4088-a3e2-b58fd5364e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tokens', 'labels'],\n",
       "    num_rows: 10747\n",
       "})"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "bc8e0916-8b25-4949-9edf-668b42aff2ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': {'input_ids': tensor([ 101, 3851, 1555, 7213, 6121,  821,  689,  928, 6587, 6956, 1383, 5439,\n",
       "          3424, 1300, 1894, 1156,  794, 1369,  671,  702, 6235, 2428, 2190,  758,\n",
       "          6887, 7305, 3546, 6822, 6121,  749, 6237, 6438,  119,  102,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0]),\n",
       "  'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0])},\n",
       " 'labels': tensor([-100,    5,   32,   32,   23,   18,   18,   18,   18,   18,    9,   15,\n",
       "            8,   18,   18,   18,   18,   18,   18,   18,   18,   18,   18,   18,\n",
       "           18,   18,   18,   18,   18,   18,   18,   18,   18, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100])}"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf4fb5f-f8c9-4272-a806-3b14dc94341c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 处理为span格式 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c1a74b5d-96a7-4280-9ca5-653b483ff293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label2span(data_ls):\n",
    "    dataset = {'text':[], 'tokens': [], 'spans':[]}\n",
    "    for data in data_ls:\n",
    "        dataset['text'].append([data['text']])\n",
    "        dataset['tokens'].append([s for s in data['text']])\n",
    "        spans = []\n",
    "        for label in data['label']:\n",
    "            for ent in data['label'][label]:\n",
    "                for offset in data['label'][label][ent]:\n",
    "                    spans.append([label, str(offset[0]), str(offset[1]), ent])\n",
    "        dataset['spans'].append(spans)\n",
    "    return dataset\n",
    "                    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0a9121dd-463a-4970-9261-b16ff5575997",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = label2span(train_data)\n",
    "val_dict =label2span(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0688b90d-7760-44f7-b1d0-f3d285817e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['organization', '0', '3', '那不勒斯'],\n",
       " ['organization', '6', '8', '锡耶纳'],\n",
       " ['organization', '11', '12', '桑普'],\n",
       " ['organization', '15', '17', '热那亚']]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dict['spans'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a970d667-4689-4722-b658-0d7f830b7617",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_dict(train_dict)\n",
    "val_ds = Dataset.from_dict(val_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e0fdf4d9-aed0-48a1-b209-08afa9cfa0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DatasetDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "306a7042-a0bb-44b1-902f-a225cb1515f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['train'] = train_ds\n",
    "ds['validation'] = val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "31e0b223-eda1-45dd-999a-19c8888f59a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'tokens', 'spans'],\n",
       "        num_rows: 10747\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'tokens', 'spans'],\n",
       "        num_rows: 1343\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "3ae74018-2691-4bf5-adc8-747e26b0cd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.save_to_disk('clue_ner_span')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "b21ed1ed-622a-451d-9450-1ac014730d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.load_from_disk('clue_ner_span')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "7c7875ae-466f-4029-b039-c1bcc14e7248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['浙商银行企业信贷部叶老桂博士则从另一个角度对五道门槛进行了解读.'], 'tokens': ['浙', '商', '银', '行', '企', '业', '信', '贷', '部', '叶', '老', '桂', '博', '士', '则', '从', '另', '一', '个', '角', '度', '对', '五', '道', '门', '槛', '进', '行', '了', '解', '读', '.'], 'spans': [['name', '9', '11', '叶老桂'], ['company', '0', '3', '浙商银行']]}\n"
     ]
    }
   ],
   "source": [
    "print(ds['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "aca31dbe-65b3-48ef-8f5a-c3c7729709e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_labels = sorted(set([span[0] for spans in ds['train']['spans'] for span in spans]))\n",
    "label2id = {label: i for i, label in enumerate(set_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "51735ec5-653b-4508-95ee-df2e4ebea837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'address': 0,\n",
       " 'book': 1,\n",
       " 'company': 2,\n",
       " 'game': 3,\n",
       " 'government': 4,\n",
       " 'movie': 5,\n",
       " 'name': 6,\n",
       " 'organization': 7,\n",
       " 'position': 8,\n",
       " 'scene': 9}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "aa619d90-3d0d-46e5-8746-189bef5df7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_transform(example):\n",
    "\n",
    "        tokens = example['tokens'][0]\n",
    "        inputs = tokenizer(\n",
    "            tokens, \n",
    "            add_special_tokens=False,\n",
    "            is_split_into_words=True, \n",
    "            padding='max_length',  \n",
    "            max_length=50)\n",
    "        inputs = dict(zip(inputs.keys(), map(torch.tensor, inputs.values())))\n",
    "        spans = example['spans'][0]\n",
    "        span_ids = torch.zeros(len(label2id), 50, 50)\n",
    "        for span in spans :\n",
    "            span_ids[label2id[span[0]],  int(span[1]), int(span[2])] = 1\n",
    "        return {'inputs':[inputs], 'span_ids':[span_ids]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "80b9e233-d725-48d3-9efd-fa911a32d6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.set_transform(set_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "960c82aa-86df-407d-861f-8900b991229f",
   "metadata": {},
   "outputs": [],
   "source": [
    "id1 = ds['train'][0]['span_ids']\n",
    "id2 = ds['train'][1]['span_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "689294ff-f34b-4025-830f-27af25a08575",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = []\n",
    "ls.append(id1)\n",
    "ls.append(id2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "3db6e247-0ef8-45cb-b215-01427c2b682b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 50, 50])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(ls).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "47f66e33-a362-44d2-9bab-3849e7cac41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1.])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids[ids.gt(0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "491d4776-fb3a-4e2a-aeb7-b108daf74ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 50, 50])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e8d71c61-5c99-4c48-b22f-896434584817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "  adding: clue_ner_span/ (stored 0%)\n",
      "  adding: clue_ner_span/train/ (stored 0%)\n",
      "  adding: clue_ner_span/train/state.json (deflated 41%)\n",
      "  adding: clue_ner_span/train/dataset_info.json (deflated 74%)\n",
      "  adding: clue_ner_span/train/dataset.arrow (deflated 56%)\n",
      "  adding: clue_ner_span/dataset_dict.json (stored 0%)\n",
      "  adding: clue_ner_span/validation/ (stored 0%)\n",
      "  adding: clue_ner_span/validation/state.json (deflated 40%)\n",
      "  adding: clue_ner_span/validation/dataset_info.json (deflated 74%)\n",
      "  adding: clue_ner_span/validation/dataset.arrow (deflated 54%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r clue_ner_span.zip clue_ner_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "0a368b73-daa0-47f8-b8b8-99b492981977",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = torch.tensor([0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "f14d81f2-5c15-4fd0-b9fd-009ae4e3b1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts[0] =1\n",
    "ts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
