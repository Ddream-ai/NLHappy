{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3276e5ef-27d7-4a3f-a4af-984c3ba8fe5c",
   "metadata": {},
   "source": [
    "# CLUE-NER数据预处理\n",
    "- 数据分析\n",
    "- 数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90da426-f64a-4657-a3ce-fd43954d1c52",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35dd14bf-da2d-4dab-b672-313a3b844381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import srsly\n",
    "from datasets import Dataset, load_from_disk, DatasetDict, ClassLabel, Sequence\n",
    "from transformers import AutoTokenizer, DataCollatorForTokenClassification\n",
    "from spacy.training import offsets_to_biluo_tags\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ebefbb9-727e-4d18-816c-37c2d4644c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = list(srsly.read_jsonl('cluener/train.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1e3ee9d-f585-4267-be4f-20909e157f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0]['text'] = '浙商银行企业信贷部叶老桂博士则从另一个角度对五道门槛进行了解读.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deb83cb2-5c7f-4378-ba9c-5aae568b4616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'浙商银行企业信贷部叶老桂博士则从另一个角度对五道门槛进行了解读.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68409f01-e6f0-4e04-bc47-16842990fbf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '据了解，日前有媒体上刊发了题为《招商银行：投资永隆银行浮亏逾百亿港元》的文章，',\n",
       " 'label': {'book': {'《招商银行：投资永隆银行浮亏逾百亿港元》': [[15, 34]]},\n",
       "  'company': {'招商银行': [[16, 19]], '永隆银行': [[23, 26]]}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[1506]  #这个数据出现了嵌套 删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "156427d6-7efe-42ca-a630-b19c700beed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_data[1506]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "113f32f8-c3a1-4370-93f9-6c84994b0813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '姜山：切沃在迎战近况极佳的尤文之前刚刚换帅，不过亚齐尼的接任者也很难给人太多的信心———',\n",
       " 'label': {'organization': {'切沃': [[3, 4]], '尤文': [[13, 14]]},\n",
       "  'name': {'姜山': [[0, 1]], '亚齐尼': [[24, 26]]}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[1506]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "057d65c2-df7f-435e-8313-3570aa0b82b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = list(srsly.read_jsonl('cluener/dev.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2738a3ff-1e86-4de4-ae7b-4770c3e81303",
   "metadata": {},
   "source": [
    "## 数据分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "324d3f9a-530f-4305-8334-84179d70e054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_df(data):\n",
    "    data_ls = []\n",
    "    for d in data:\n",
    "        text = d['text']\n",
    "        for label in d['label']:\n",
    "            for span in d['label'][label]:\n",
    "                start_index = d['label'][label][span][0][0]\n",
    "                end_index = d['label'][label][span][0][1]\n",
    "                data_ls.append([text, span, label, start_index, end_index])\n",
    "    return pd.DataFrame(data_ls, columns=['text', 'span','label', 'start', 'end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b34325ec-6759-4659-8b6d-b1919e1d054b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = to_df(train_data)\n",
    "valid_df = to_df(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2256a21d-745c-4237-af9a-1303ce7e0271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name            451\n",
       "position        425\n",
       "company         366\n",
       "address         364\n",
       "organization    344\n",
       "game            287\n",
       "government      244\n",
       "scene           199\n",
       "book            152\n",
       "movie           150\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5e7cd7-082f-4f8c-8661-6924b2fd5913",
   "metadata": {},
   "source": [
    "## 数据处理为huggingface 和 spacy 格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "53046965-cf84-4f13-b131-3affb5528d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank('zh')\n",
    "def process(data_ls):\n",
    "    dataset = {'tokens':[], 'labels':[]}\n",
    "    docs = []\n",
    "    for data in tqdm(data_ls):\n",
    "        entities = []\n",
    "        dataset['tokens'].append([s for s in data['text']])\n",
    "        doc = nlp(data['text'])\n",
    "        spans = []\n",
    "        for label in data['label']:\n",
    "            for ent in data['label'][label]:\n",
    "                entity = []\n",
    "                entity.append(data['label'][label][ent][0][0])\n",
    "                entity.append(data['label'][label][ent][0][1]+1)\n",
    "                entity.append(label)\n",
    "                entities.append(entity)\n",
    "                e_span = spacy.tokens.Span(doc, data['label'][label][ent][0][0], data['label'][label][ent][0][1]+1, label)\n",
    "                spans.append(e_span)\n",
    "        doc.set_ents(spans)\n",
    "        docs.append(doc)\n",
    "        tags = [t.ent_iob_ if t.ent_iob_ == 'O' else t.ent_iob_ + '-' + t.ent_type_ for t in doc ]\n",
    "        dataset['labels'].append(tags)\n",
    "    return dataset, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "526013d7-4472-45d4-939c-b6c50eb635a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10747/10747 [00:01<00:00, 7726.99it/s]\n",
      "100%|██████████| 1343/1343 [00:00<00:00, 10430.48it/s]\n"
     ]
    }
   ],
   "source": [
    "train_ds, train_docs= process(train_data)\n",
    "valid_ds, valid_docs = process(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b135b197-8eca-4290-9c83-f9d5a4c51a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-game',\n",
       " 'I-game',\n",
       " 'I-game',\n",
       " 'I-game',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds['labels'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "b4c94fc5-654f-468c-8b74-c1995fc88ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sp, valid_sp = DocBin(docs=train_docs), DocBin(docs=valid_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "0f168259-8511-44fd-a51d-4ce18c784809",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sp.to_disk('cluener_train.spacy')\n",
    "valid_sp.to_disk('cluener_valid.spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "9c7577a3-7c6b-4a79-bb02-6ff98953baed",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(DocBin().from_disk(path='cluener_train.spacy').get_docs(nlp.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "b2c457e6-4c6a-4b25-977d-56a311c5b617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "浙商银行企业信贷部叶老桂博士则从另一个角度对五道门槛进行了解读."
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d474ac25-6b2d-48cd-8782-702eaf209e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hf = Dataset.from_dict(train_ds)\n",
    "valid_hf = Dataset.from_dict(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8fbf380a-08e8-46ce-ba0e-a0cfb1274d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict()\n",
    "dataset['train'] = train_hf\n",
    "dataset['validation'] = valid_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f3fde513-1ead-44c6-8965-fb0f0ec40aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.save_to_disk('clue_ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e88d74b5-1131-42a9-864b-d0f258b44341",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_from_disk('clue_ner/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46ae4f70-552b-4e1f-a589-3cb5f8b8da6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_labels = set([label for labels in ds['train']['labels'] for label in labels])\n",
    "label2id = sorted({label:id for id,label in enumerate(set_labels)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eeecfbb8-e39c-4877-af57-8e7e63c98526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-address',\n",
       " 'B-book',\n",
       " 'B-company',\n",
       " 'B-game',\n",
       " 'B-government',\n",
       " 'B-movie',\n",
       " 'B-name',\n",
       " 'B-organization',\n",
       " 'B-position',\n",
       " 'B-scene',\n",
       " 'I-address',\n",
       " 'I-book',\n",
       " 'I-company',\n",
       " 'I-game',\n",
       " 'I-government',\n",
       " 'I-movie',\n",
       " 'I-name',\n",
       " 'I-organization',\n",
       " 'I-position',\n",
       " 'I-scene',\n",
       " 'O']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f7c80086-eb46-4db2-8c18-39ae36bc6e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "srsly.write_json('clue_ner/label2id.json', label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "ddc1c237-2c5c-47a9-a155-59fdfb52c997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_transform(example):\n",
    "        tokens = example['tokens'][0]\n",
    "        inputs = tokenizer(tokens, is_split_into_words=True, padding='max_length', max_length=50)\n",
    "        inputs = dict(zip(inputs.keys(), map(torch.tensor, inputs.values())))\n",
    "        labels = example['labels'][0]\n",
    "        # print(labels)\n",
    "        labels = [-100] + [label2id[label] for label in labels] \n",
    "        labels = labels + (50 - len(labels)) * [-100]\n",
    "        labels = torch.tensor(labels)\n",
    "        assert len(labels) == len(inputs['input_ids'])\n",
    "        return {'inputs':[inputs], 'labels':[labels]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "ffba2e83-16b9-414c-869c-88e1d59cf56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.set_transform(set_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "ae412c86-db99-4088-a3e2-b58fd5364e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tokens', 'labels'],\n",
       "    num_rows: 10747\n",
       "})"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "bc8e0916-8b25-4949-9edf-668b42aff2ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': {'input_ids': tensor([ 101, 3851, 1555, 7213, 6121,  821,  689,  928, 6587, 6956, 1383, 5439,\n",
       "          3424, 1300, 1894, 1156,  794, 1369,  671,  702, 6235, 2428, 2190,  758,\n",
       "          6887, 7305, 3546, 6822, 6121,  749, 6237, 6438,  119,  102,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0]),\n",
       "  'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0])},\n",
       " 'labels': tensor([-100,    5,   32,   32,   23,   18,   18,   18,   18,   18,    9,   15,\n",
       "            8,   18,   18,   18,   18,   18,   18,   18,   18,   18,   18,   18,\n",
       "           18,   18,   18,   18,   18,   18,   18,   18,   18, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100])}"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "1517eb67-1b1c-4330-9d6c-492029f8e0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "59331a1e-d2d6-48a3-aec2-9c83acd7b3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset=ds['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "2639395c-0f2e-48f8-9ad3-6f34e9f998bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': {'input_ids': tensor([[ 101, 3851, 1555, 7213, 6121,  821,  689,  928, 6587, 6956, 1383, 5439,\n",
       "           3424, 1300, 1894, 1156,  794, 1369,  671,  702, 6235, 2428, 2190,  758,\n",
       "           6887, 7305, 3546, 6822, 6121,  749, 6237, 6438,  119,  102,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0]]),\n",
       "  'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0]]),\n",
       "  'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0]])},\n",
       " 'labels': tensor([[-100,    5,   32,   32,   23,   18,   18,   18,   18,   18,    9,   15,\n",
       "             8,   18,   18,   18,   18,   18,   18,   18,   18,   18,   18,   18,\n",
       "            18,   18,   18,   18,   18,   18,   18,   18,   18, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100]])}"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1dcc3ef5-50ad-4f86-9343-234e3769a6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: clue_ner/ (stored 0%)\n",
      "  adding: clue_ner/train/ (stored 0%)\n",
      "  adding: clue_ner/train/state.json (deflated 40%)\n",
      "  adding: clue_ner/train/dataset_info.json (deflated 67%)\n",
      "  adding: clue_ner/train/dataset.arrow (deflated 68%)\n",
      "  adding: clue_ner/dataset_dict.json (stored 0%)\n",
      "  adding: clue_ner/label2id.json (deflated 55%)\n",
      "  adding: clue_ner/validation/ (stored 0%)\n",
      "  adding: clue_ner/validation/state.json (deflated 40%)\n",
      "  adding: clue_ner/validation/dataset_info.json (deflated 67%)\n",
      "  adding: clue_ner/validation/dataset.arrow (deflated 66%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r clue_ner.zip clue_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "6898406f-6b9a-4d88-939f-8d0f471c068d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [4381, 671, 4381, 8405, 8798], 'token_type_ids': [0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1], 'offset_mapping': [(0, 1), (1, 2), (2, 3), (3, 5), (5, 7)]}"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('玩一玩cdol', return_offsets_mapping=True, add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c7e7d9-318c-4c6f-9f80-116de2f234e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
