{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "b16b5da1-1fd2-407c-866b-5b0d4884dfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast, AutoTokenizer, BertModel\n",
    "import srsly\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset, DatasetDict, load_from_disk\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "1c0d3f2b-0b0f-4596-966c-d2b0b8e6727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "2da95bd7-15d6-462c-9dcc-9013a4bc2fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab['[BLANK]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "f223e210-a7c2-40c0-b7e5-936d3b081ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 143, 1, 102]"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(['a', '[BLANK]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "d85c9850-5a43-4465-b894-4eacdceb8f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = list(srsly.read_jsonl('cluener/train.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "c7ed10e0-c04a-4d58-b93b-6b4aca6436bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = list(srsly.read_jsonl('cluener/dev.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "3597295a-3a02-46f0-bdbd-c26785c46e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(data_ls):\n",
    "    dataset = {'text':[], 'spans':[], }\n",
    "    for data in tqdm(data_ls):\n",
    "        dataset['text'].append(data['text'])\n",
    "        entities = []\n",
    "        # mapping = tokenizer(data['text'], add_special_tokens=False, return_offsets_mapping=True)['offset_mapping']\n",
    "        # tokens = tokenizer.tokenize(data['text'], add_special_tokens=False)\n",
    "        # dataset['tokens'].append(tokens)\n",
    "        # spans = []\n",
    "        for label in data['label']:\n",
    "            for ent in data['label'][label]:\n",
    "                for span in data['label'][label][ent]:\n",
    "                    char_start = span[0]\n",
    "                    char_end = span[1]\n",
    "                    entity = []\n",
    "                # # try:\n",
    "                # for i, v in enumerate(mapping):\n",
    "                #     if v[0] == char_start and v[1] == char_end:\n",
    "                #         entity.append(i)\n",
    "                #         entity.append(i+1)\n",
    "                #     if v[0] == char_start and v[1]!= char_end:\n",
    "                #         entity.append(i)\n",
    "                #     elif v[1] == char_end and v[0] != char_start:\n",
    "                #         entity.append(i)\n",
    "                    entity.append(char_start)\n",
    "                    entity.append(char_end)\n",
    "                    entity.append(label)\n",
    "                    entity.append(ent)\n",
    "                # print(entity)\n",
    "                    entity = list(map(str, entity))\n",
    "                    assert len(entity) == 4, (data, tokens)\n",
    "                # except AssertionError:\n",
    "                #     print(entity)\n",
    "                    entities.append(entity)\n",
    "        dataset['spans'].append(entities)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "895fb285-f46c-46ea-b6a4-4f4e255227c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10748/10748 [00:00<00:00, 161794.73it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dict = process(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "081a6bec-bcf8-43f7-ae05-029a22e02719",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1343/1343 [00:00<00:00, 87983.23it/s]\n"
     ]
    }
   ],
   "source": [
    "val_dict = process(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "484d777a-1028-46b0-a4a7-eb3b596863d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = Dataset.from_dict(train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "baf88c30-583b-4429-ba1d-679062d62761",
   "metadata": {},
   "outputs": [],
   "source": [
    "valset = Dataset.from_dict(val_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "31dd5b68-84c7-4024-9d01-fecd68b5c3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '会议批准了中国与欧盟海军、多国海上力量和北约等就在“国际推荐通行走廊”', 'spans': [['5', '11', 'government', '中国与欧盟海军'], ['20', '21', 'government', '北约']]}\n"
     ]
    }
   ],
   "source": [
    "print(trainset[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "f96e1b8c-0f6c-4552-9b88-972dcc478827",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DatasetDict()\n",
    "ds['train'] = trainset\n",
    "ds['validation'] = valset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "e9948993-2a68-4107-a777-60ca8fab954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.save_to_disk('clue_ner_charspan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "04f2b18e-6a52-4071-b263-e7151e33d671",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_from_disk('clue_ner_charspan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "d65c42d0-0c3f-4a6c-93ae-73daec3bee6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '她写道：抗战胜利时我从重庆坐民联轮到南京，去中山陵瞻仰，也到秦淮河去过。然后就去北京了。',\n",
       " 'spans': [['11', '12', 'address', '重庆'],\n",
       "  ['18', '19', 'address', '南京'],\n",
       "  ['40', '41', 'address', '北京'],\n",
       "  ['22', '24', 'scene', '中山陵'],\n",
       "  ['30', '32', 'scene', '秦淮河']]}"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][17]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
